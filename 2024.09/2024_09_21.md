## Today I Learned (2024-09-21)
---
> ## 목차
- [Today I Learned (2024-09-21)](#today-i-learned-2024-09-21)
- [오늘 공부한 내용](#오늘-공부한-내용)
  - [1. 머선러닝](#1-머선러닝)
    - [Voting 이해하기](#voting-이해하기)
    - [Hard Voting Classifier](#hard-voting-classifier)
    - [Soft Voting Classifier](#soft-voting-classifier)
    - [Bootstrap](#bootstrap)
    - [Out-Of-Bag 샘플](#out-of-bag-샘플)
    - [OOB 스코어](#oob-스코어)
    - [ROC Curve 란](#roc-curve-란)
    - [ROC Curve 와 AUC](#roc-curve-와-auc)
  - [2. 데이터분석](#2-데이터분석)
    - [EDA(Exploratory Data Analysis)](#edaexploratory-data-analysis)
  - [3. KDT](#3-kdt)
    - [챗봇 성능 향상 시키기](#챗봇-성능-향상-시키기)
- [어려웠던 내용](#어려웠던-내용)
- [궁금한 내용과 부족한 내용](#궁금한-내용과-부족한-내용)
- [느낀 점](#느낀-점)
---

## 오늘 공부한 내용
### 1. 머선러닝
#### Voting 이해하기
- Voting Classifier
  - 일종의 앙상블(ensemble) 의 또다른 기법으로(Bagging,Boosting), 여러 모델들을 기반으로, 투표를 하는 Voting 기법이 있음
  - 해당 기법을 사용하여 성능이 괜찮은 모델을 기반으로 Voting 을 해서, 또다른 예측 모델을 구성할 수 있음
  - Voting 기법도 크게 `Hard Voting` 기법과 `Soft Voting` 기법이 존재함

#### Hard Voting Classifier
- 여러 모델이 예측한 분류 중, 가장 많은 모델이 예측한 분류를 선택하는 기법
- 즉, 가장 표를 많이 받은 것을 선택

#### Soft Voting Classifier
- 여러 모델을 확률로 예측 분류한 후, 예측 확률의 평균을 내어, 확률이 가장 높은 분류를 선택하는 기법
- 즉, 예측 분류 후 예측 확률의 평균을 내어, 가장 확률이 높은 것을 선택

#### Bootstrap
- 주어진 샘플 데이터셋에서, 중복을 허용하여 무작위로 임의 샘플셋을 복수개로 만들고, 이를 통해, 분포, 신뢰구간과 같은 통계값을 계산하여, 모집단 또는 주어진 샘플 데이터셋보다 큰 데이터에 대한 분포등을 추정하는 기법

#### Out-Of-Bag 샘플
- 보통 Bootstrap Aggregation 기법을 사용하여, 샘플 세트를 만들 경우, 평균적으로 훈련 세트의 3분의 2를 사용함
    - 샘플 세트를 만들 때, 복원 추출(원 데이터에서 샘플을 선택하므로, 중복 선택된 샘플이 있을 수 있다는 의미)을 사용하기 때문임
- 나머지 사용되지 않은 3분의 1을 Out-Of-Bag 샘플이라고 이야기함
- 이러한 OOB 샘플을 데이터 세트처럼, 만들어진 모델에 넣어서 예측 결과를 평가할 수 있음

#### OOB 스코어
- OOB 샘플들의 실제 값과, 트리로 부터 나온 예측 값 사이의 오차를 기반으로 정확도 계산 가능

```markdown
OOB 스코어는 학습에 쓰이지 않은 데이터로 정확도를 계산하므로, 보다 일반적인 정확도를 구할 수 있음
```

#### ROC Curve 란
- ROC(Receiver Operating Characteristic) Curve
- ROC Curve 란 머신러닝 성능 평가 계산 방법을 의미함

#### ROC Curve 와 AUC
- AUC(Area Under the Curve)
- AUC 는 ROC Curve 의 곡선 아래 영역을 나타내며, 머신러닝 성능평가지표로 많이 사용됨
    - 1 에 가까울 수록, 우수한 성능임을 나타냄
    - 0.5 일 경우는 분류 능력이 없는 것으로 이해해야함
    - 0.5 이하일 경우는 잘못 예측한다고 이해하면 됨
- 보통 일상에 적용되려면, AUC가 0.8 이상은 되어야 한다고 함

### 2. 데이터분석
#### EDA(Exploratory Data Analysis)
- 데이터 분석을 위해 raw data를 다양한 각도에서 관찰하여, 데이터를 이해하는 과정
  - 데이터 분석 주제마다 EDA를 통해 진행하는 과정은 각양각색이므로, 정형화된 패턴은 없지만,
  - 크게 다음과 같은 3가지 과정은 기본이 될 수 있으므로 다음 3가지 과정을 기본으로 이해하기로 함
      1. 데이터의 출처와 주제에 대해 이해
      2. 데이터의 크기 확인
      3. 데이터 구성 요소(feature)의 속성(특징) 확인
          - feature: 데이터 구성 요소를 위미함

### 3. KDT
#### 챗봇 성능 향상 시키기
- 나쁘지 않은 성능이라고 생각들지만 욕심이 난다.
	```
    정밀도(Precision): 1.00
    재현율(Recall): 0.89
    F1 Score: 0.94
    정확도(Accuracy): 0.89
    평균 응답 시간: 0.1770 초
    ```
- 검색한 것을 캐싱해서 후에 검색되는 것과 질문의 유사도를 검사해서 이후 로직을 타지 않게함.
- 비동기 처리(async)를 하게 해서 테스트 시 질문이 많이 들어가도 좋은 평가지표를 받도록 함.
- OpenAI API에서의 `temperature` 와 `top_p` 를 조정함.
  <img src="https://github.com/online5880/TIL/blob/main/Images/2024.09/2024_09_21/GPT.png?raw=true" width="100%" height="100%"/> [Cheat Sheet: Mastering Temperature and Top_p in ChatGPT API](https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683)

---
## 어려웠던 내용
- 챗봇 성능 테스트 및 최적화
---
## 궁금한 내용과 부족한 내용
- 챗봇 성능 테스트를 할때 테스트셋과 기본 샘플수가 부족한데 어떻게 처리할 수 있을지...
---
## 느낀 점
- 자연어 챗봇의 성능을 테스트할 때 샘플 수가 적으면 어쩌지?...
- 자연어 모델 학습시켜보고 싶은데 시키려니 데이터가 너무 크다

<!-- <img src="이미지 주소" width="100%" height="100%"/> -->
