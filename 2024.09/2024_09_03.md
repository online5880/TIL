## Today I Learned (2024-09-03)
---
> ## 목차
- [Today I Learned (2024-09-03)](#today-i-learned-2024-09-03)
- [오늘 공부한 내용](#오늘-공부한-내용)
  - [1. KDT (DL)](#1-kdt-dl)
    - [딥러닝 개념](#딥러닝-개념)
    - [딥러닝 모델 구축 단계](#딥러닝-모델-구축-단계)
    - [통계모델/머신러닝/딥러닝 비교표](#통계모델머신러닝딥러닝-비교표)
    - [이미지 데이터 처리](#이미지-데이터-처리)
  - [2. 머신러닝](#2-머신러닝)
    - [교차 검증(Cross Validation)](#교차-검증cross-validation)
    - [Holdout Cross Validation](#holdout-cross-validation)
    - [K-fold Cross Validation](#k-fold-cross-validation)
    - [sklearn 의 Cross Validation \& K-fold 사용법](#sklearn-의-cross-validation--k-fold-사용법)
  - [3. Pandas \& Bigquery](#3-pandas--bigquery)
    - [Bigquery 쿼리문제 풀기](#bigquery-쿼리문제-풀기)
- [어려웠던 내용](#어려웠던-내용)
- [궁금한 내용과 부족한 내용](#궁금한-내용과-부족한-내용)
- [느낀 점](#느낀-점)
---

## 오늘 공부한 내용
### 1. KDT (DL)
#### 딥러닝 개념
- 입력층, 은닉층, 출력층
  - 입력층
    - 데이터를 받아들이는 역할
  - 은닉층
    - 입력 데이터를 처리하여 패턴을 학습. 은닉층의 개수가 많을수록 모델은 더 복잡한 패턴을 학습할 수 있으며, 이는 딥러닝의 성능에 직접적인 영향을 미친다.
  - 출력층
    - 최종적으로 모델의 예측 결과를 출력하는 층
    - 출력층의 구조와 활성화 함수는 문제의 유형(예: 분류, 회귀)에 따라 달라진다.
- 지도학습
  - 딥러닝은 지도 학습에 사용되며, 데이터와 레이블을 통해 모델이 예측하거나 분류할 수 있도록 학습한다.
- 데이터 복잡도와 모델 선택
  - 데이터의 복잡도와 양에 따라 통계 모델, 머신러닝, 딥러닝 중 적절한 방법을 선택해야 한다.
  - 무조건 어떤게 좋다라는건 없다!
- CPU와 GPU 연산의 차이
  - CPU
    - 정밀한 연산
  - GPU
    - 병렬 처리가 필요한 대규모 연산에 적합하다.

#### 딥러닝 모델 구축 단계
1. 모델 정의 : 어떤 형태의 모델을 사용할지 결정 (예: Sequential model)
2. 입력층 설정 : 입력 데이터의 형태 정의(input shape)
3. 은닉층 설정 : 은닉층의 노드 수와 활성화 함수를 설정
4. 출력층 설정 : 노드 결정, 활성화 함수 선택
5. 모델 컴파일 : 최적화 함수, 손실 함수, 평가 지표 설정
6. 예측 및 검증 : 모델의 성능을 평가하고, 예측 결과를 검증
- 예시코드

```python
model = tf.keras.models.Sequential(
    [
        tf.keras.layers.Flatten(input_shape=(28, 28)),  # 입력층 
        tf.keras.layers.Dense(128,activation='relu'),   # 입력 레이어, 출력 레이어를 연결해주는 레이어
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax') # 출력층
    ]
)
```
- Flatten Layer : 1차원으로 펼쳐주는 레이어.
- Dense Layer : 입력 레이어, 출력 레이어를 연결해주는 레이어
  - activation : 활성함수
- Dropout Layer : 은닉층의 노드를 랜덤으로 꺼버린다. (cross validation 같은)

#### 통계모델/머신러닝/딥러닝 비교표
|  | 통계모델 | 머신러닝 | 딥러닝 | 비고 |
| --- | --- | --- | --- | --- |
| 데이터 복잡도 | 낮음 | 보통 | 높음 | 항상 비례하지 않음 |
| 데이터의 양 | 적음 | 보통 | 많음 | 항상 비례하지 않음 |
| 처리시간 | 짧음 | 보통 | 길음 |  |
| 연산능력 요구 | 적음 | 보통 | 많음 |  |
| 과적합 등의 위험 | 없음 | 보통 | 많음 |  |

#### 이미지 데이터 처리
- 픽셀 값을 255로 나누어 0과 1 사이의 값으로 정규화하는 것이 일반적이다.

### 2. 머신러닝
#### 교차 검증(Cross Validation)
- Cross Validation(교차 검증)
  - 머신러닝 : 학습 데이터(train)로 학습을 한 후, 테스트 데이터(test)에 대해 학습된 모델을 통해 예측값을 도출
  - 학습 데이터로 학습된 모델을 평가하고 개선하기 위해, 검증 데이터가 필요함

#### Holdout Cross Validation
- 학습 데이터를 8:2, 7:3 또는 9:1과 같이 학습 데이터와 검증 데이터로 분리하는 것
- 고정적인 검정 데이터로 모델을 평가/개선할 경우, 검증 데이터에만 overfit 될 수 있음
- 잘 쓰이지는 않는다.

#### K-fold Cross Validation
- 데이터를 k 개로 분할 (각 분할된 서브 데이터를 fold 라고 부름)
- 각 fold 를 선택하여, 해당 fold 이외의 k-1 개의 나머지 fold 로 훈련(학습)을 시킨 후에, 특정 fold 로 테스트(test)를 해서, 검증 점수를 계산함
- overfit 되는 문제를 해결할 수 있으나, 시간이 보다 오래 걸림
- 가장 많이 쓰이는 교차 검증 방법이다.
  
#### sklearn 의 Cross Validation & K-fold 사용법
- KFold(n_split, shuffle, random_state)
    - n_split : 나누는 갯수
    - shuffle : 각 그룹에 데이터를 섞는지 여부(True 면, 데이터를 섞음)
    - random_state : shuffle 이 True 일 때, 랜덤하게 데이터를 섞는데, 이 때 random_state 값을 정수 값으로 설정하면, 이에 따라 랜덤값이 만들어지므로, 여러번 실행해도 동일한 랜덤값으로 동일하게 각 그룹에 데이터를 섞음
- cross_val_score(estimator, x, y cv, n_jobs, scoring)
    - estimator : 모델 객체를 넣어주면 됨 (학습할 모델을 의미함)
    - x : train 데이터(feature 값)
    - y : train 데이터의 실제 값
    - cv : 정수 또는 KFold 와 같은 객체명
    - n_jobs : -1 이면 모든 CPU 코어를 사용해서 병렬 수행, 정수면 병렬 사용할 CPU 코어수(병렬수행)
    - scoring : 모델 평가식을 선택 (보통 ‘accuracy’ 사용)
    - cross_val_score() 의 리턴값은 scoring 계산식을 통해, 계산된 각 그룹에 대한 모델 평가값(’accuracy’면 예측 정확도)을 배열로 반환
- Stratified cross validation
    - 데이터가 몰려 있을 경우(편향되어 있을 경우), 단순 k-fold 교차검증으로는 적잘한 검증 점수를 계산하기 어려움
    - 원본 데이터의 레이블 분포에 동일한 분포를 가지도록 fold 를 구성하여, 검증하는 것
        - 예를 들어, A와 B로 이루어진 원본 데이터의 구성 비율이 A:B = 2:8 이라면, 각 fold 도 A와 B 가 2:8이 되도록 만들어주는 기법
    - 함수 인자로는 n_splits, shuffle, random_state 를 가짐

### 3. Pandas & Bigquery
#### Bigquery 쿼리문제 풀기
- dataset 에 있는 `thelook_ecommerce` 데이터 쿼리 문제 풀기

```SQL
-- Q1. 2023년 가입 유저수
SELECT *
FROM `bigquery-public-data.thelook_ecommerce.users`
WHERE created_at BETWEEN '2023-01-01' AND '2024-01-01';

-- Q2. 브라우저별 세션 수
SELECT browser, COUNT(session_id) AS total_session
FROM `bigquery-public-data.thelook_ecommerce.events`
GROUP BY browser
ORDER BY total_session DESC;

-- Q3. 2023년 월별 매출액(sale_price*num_of_item), 주문수, 주문 유지수 계산
SELECT 
EXTRACT(MONTH FROM A.created_at) AS month, 
SUM(A.sale_price * B.num_of_item) AS revenue,
COUNT(DISTINCT A.order_id) AS order_count, 
COUNT(DISTINCT A.user_id) AS customers_purchased
FROM `bigquery-public-data.thelook_ecommerce.order_items` A
LEFT OUTER JOIN `bigquery-public-data.thelook_ecommerce.orders` B ON A.order_id = B.order_id
WHERE A.status NOT IN ('Cancelled','Returned') AND A.created_at BETWEEN '2023-01-01' AND '2024-01-01'
GROUP BY EXTRACT(MONTH FROM A.created_at)
ORDER BY month;

-- Q4. order_items에서 status가 Cancelled, Returned 된 상품들의 남녀로 나누어서 매출액(sale_price*num_of_items), 수량 계산하기
SELECT B.gender, SUM(A.sale_price * B.num_of_item) AS revenue, SUM(B.num_of_item) AS quantity
FROM `bigquery-public-data.thelook_ecommerce.order_items` A
LEFT OUTER JOIN `bigquery-public-data.thelook_ecommerce.orders` B ON A.order_id = B.order_id
WHERE A.status IN ('Cancelled','Returned') AND A.created_at BETWEEN '2023-01-01' AND '2024-01-01'
GROUP BY B.gender
ORDER BY revenue;
```

---
## 어려웠던 내용
- 딥러닝은 낯설다. 어려울거같다.
- 머신러닝 검증은 아직 잘 이해가 되지 않는다... 일단 1에 가까우면 굿
---
## 궁금한 내용과 부족한 내용
- 빅쿼리의 활용도
---
## 느낀 점
- 딥러닝 앞으로 어떨지 궁금하다.
- 빅쿼리. 느리다. 어떻게 쓰는거지?.

<!-- <img src="이미지 주소" width="100%" height="100%"/> -->
