## Today I Learned (2024-08-27)
---
> ## 목차
- [Today I Learned (2024-08-27)](#today-i-learned-2024-08-27)
- [오늘 공부한 내용](#오늘-공부한-내용)
  - [1. KDT (ML)](#1-kdt-ml)
    - [회귀 모델 평가 지표](#회귀-모델-평가-지표)
    - [분류 모델 평가 지표](#분류-모델-평가-지표)
    - [추천 시스템 모델의 평가 지표](#추천-시스템-모델의-평가-지표)
    - [과적합이 일어나는 이유](#과적합이-일어나는-이유)
    - [과적합 감지](#과적합-감지)
    - [과적합 방지](#과적합-방지)
    - [과소적합](#과소적합)
    - [불균형 데이터 처리 imbalanced-learn](#불균형-데이터-처리-imbalanced-learn)
- [어려웠던 내용](#어려웠던-내용)
- [궁금한 내용과 부족한 내용](#궁금한-내용과-부족한-내용)
- [느낀 점](#느낀-점)
---

## 오늘 공부한 내용
### 1. KDT (ML)
#### 회귀 모델 평가 지표
- MAE(Mean Absolute Error)
  - 모델의 예측값과 실제값의 차이의 절대값의 평균
  - 절대값을 취하기 때문에 가장 직관적으로 알 수 있는 지표이다.
  - 오차가 커졌을 때 상대적으로 중요하지 않게 나타날 수 있다.

    <img src="https://github.com/online5880/TIL/blob/main/Images/2024.08/2024_08_27/MAE.png?raw=true" width="30%" height="100%"/> 

- MSE(Mean Squared Error)
  - 오차카 커질수록 가중치가 커진다.
  - 오차가 큰 값일 경우 더 안좋다라는 걸 직관적으로 숫자로 나타낼 수 있다.
  - 제곱을 하기 때문에 아웃라이너에 민감하다.
  
    <img src="https://github.com/online5880/TIL/blob/main/Images/2024.08/2024_08_27/MSE.png?raw=true" width="30%" height="100%"/> 

- RMSE(Root Mean Squared Error)
  - MSE에 루트를 씌워 사용한다.
  - RMSE를 사용하면 오류 지표를 실제값과 유사한 단위로 다시 변환하여 해석을 쉽게한다.

    <img src="https://github.com/online5880/TIL/blob/main/Images/2024.08/2024_08_27/RMSE.png?raw=true" width="30%" height="100%"/> 

- 참고 사이트 및 이미지 출처
  - [회귀의 오류 지표 알아보기](https://modulabs.co.kr/blog/regression_metrics_mae_mse/)

#### 분류 모델 평가 지표
- confusion matrix(오차 행렬)
  - 분류를 하면서 얼마나 헷갈리고 있는지 알려준다.
  - 어떤 예측오류가 얼마나 발생하는지 알 수 있다.
  
   <img src="https://github.com/online5880/TIL/blob/main/Images/2024.08/2024_08_27/confusion_matrix.png?raw=true" width="100%" height="100%"/> 

- Acuuracy(정확도)
  - 전체 데이터 중 올바르게 예측한 비율
- Recall(재현율)
  - 실제 true 중 예측 true의 비율
- Precision(정밀도)
  - 예측 true 중 실제 true의 비율
- F1 Score
  - 재현율과 정밀도의 조화평균
  - 재현율과 정밀도가 얼마나 조화를 이루는지, 한쪽으로 치우치지 않았는지를 나타낸다.
  - 한쪽으로 치우치면 F1 Score의 값이 낮게 나온다.
  - [출처:분류 모델의 평가 방법](https://velog.io/@skyepodium/%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80-%EB%B0%A9%EB%B2%95)

#### 추천 시스템 모델의 평가 지표
- 선호/비선호 분류 모델 기반 평가 모델
- Precision@k
  - k번 추천을 해서 선호하는 아이템을 몇번이나 추천을 했는가
  - 내 선호 목록에서 몇개나 맞췄는가
  - 추천을 적게하고 최대한 많이 맞추는게 좋은 지표
- Recall@k
  - 내 선호 아이템 중 얼마나 많이 맞췄는가

#### 과적합이 일어나는 이유
- 트레이닝 셋이 작을 때
- 특정 클래스의 개수가 적거나 없을 때
- 훈련할 대상에서 너무 많은 정보를 입력할 때
- 모델의 복잡도가 데이터의 복잡도가 지나치게 높은 경우
- 데이터셋의 다양성? 폭넓게 준비해야하는데 그렇지 못한경우

#### 과적합 감지
- k-fold cross validation (교차 검증)
    - 데이터가 너무 작아질 수 있다. → 많이 쪼개면
    - 평가지표가 확 떨어지면 과대적합을 의심할 수 있다.
    - 교차 검증을 했을 때 지나치게 떨어지거나 올라가면 과대적합 의심

#### 과적합 방지
- 프루닝
    - 전처리 과정에서 관계 있는 데이터를 넣고, 관계 없는 데이터는 뺀다.
- 정규화
- 앙상블링
- 데이터 증강
    - 대체로 현실적이지 않다.

#### 과소적합
- 과소적합은 데이터의 편향성이 높다.
- 과대적합은 분산이 높다.
- 머신러닝에서는 보통 9:1 비율로 과대적합이 일어난다.
- 머신러닝 약간의 과적합을 일으키는 것을 목표로 한다.
    - 납득 가능한 부분의 과대적합이 일어나면 무시해도 된다.

#### 불균형 데이터 처리 imbalanced-learn
- 데이터를 배로 늘리는 것은 안해야함
- 데이터를 늘리는 방향의 데이터처리는 잘 이루어지지 않는다.
- 데이터를 같이 줄이고 늘리고 한다.
- 패키지 이름
  - imlearn 
- 불균형 처리에 강한 모델
  - catboost - categorical 데이터를 전처리 없이 집어넣을 수 있는
  - emsemble - 대체로 imbalanced 에 강한 모습을 보인다.
- 심하게 나타나는 경우
  - 작은 숫자의 그룹이 숫자가 적을 때 (10000:1, 1000000:100000000)
- **일단은 데이터가 많아야한다.**

---
## 어려웠던 내용
- 보고서 수정 및 피드백 받기...
---
## 궁금한 내용과 부족한 내용
- 데이터분석 경험 머신러닝 경험 부족
---
## 느낀 점
- 이제 수학이 나오나? ....

<!-- <img src="이미지 주소" width="100%" height="100%"/> -->
https://github.com/online5880/TIL/blob/main/Images/2024.08/2024_08_27/MAE.png?raw=true