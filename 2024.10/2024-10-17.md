## Today I Learned (2024-10-17)
---
> ## 목차
- [Today I Learned (2024-10-17)](#today-i-learned-2024-10-17)
- [오늘 공부한 내용](#오늘-공부한-내용)
  - [1. KDT (NLP)](#1-kdt-nlp)
    - [자연어 처리 모델 (NLP, Natural Language Processing)](#자연어-처리-모델-nlp-natural-language-processing)
    - [NLP 모델의 발전](#nlp-모델의-발전)
    - [벡터화 (Vectorization)](#벡터화-vectorization)
    - [벡터화 종류](#벡터화-종류)
    - [관련 용어](#관련-용어)
    - [Word2Vec](#word2vec)
    - [Transformer 모델](#transformer-모델)
    - [주요 개념](#주요-개념)
    - [생성형 AI (Generative AI)](#생성형-ai-generative-ai)
    - [LLM(대규모 언어 모델) 관련 용어](#llm대규모-언어-모델-관련-용어)
    - [LLM 평가 기준](#llm-평가-기준)
    - [LLM 응답 방식](#llm-응답-방식)
    - [프롬프트 엔지니어링](#프롬프트-엔지니어링)
    - [성공적인 프롬프트의 조건](#성공적인-프롬프트의-조건)
    - [프롬프트 유형](#프롬프트-유형)
    - [Fine-tuning과 RAG](#fine-tuning과-rag)
    - [문서 검색 시스템](#문서-검색-시스템)
    - [Huggingface Transformers 라이브러리](#huggingface-transformers-라이브러리)
  - [2. ADsP](#2-adsp)
  - [3. SQLD](#3-sqld)
- [어려웠던 내용](#어려웠던-내용)
- [궁금한 내용과 부족한 내용](#궁금한-내용과-부족한-내용)
- [느낀 점](#느낀-점)
---

## 오늘 공부한 내용
### 1. KDT (NLP)
#### 자연어 처리 모델 (NLP, Natural Language Processing)

#### NLP 모델의 발전

- **초기 모델**: LSTM 기반으로 시계열 분석 가능.
- **발전 모델**: CNN + LSTM으로 복잡한 작업 가능.
- **Seq2Seq 모델**: 텍스트 시퀀스 분석을 통해 챗봇 등 다양한 응용 등장.
- **Transformer 모델**: Attention 메커니즘 기반, 이전 발화 정보를 저장하며 성능 향상. 
    - **대표 모델**: BERT, GPT, T5, Polyglot, LLama 등.

#### 벡터화 (Vectorization)

자연어 시퀀스를 컴퓨터가 처리할 수 있는 벡터 형태로 변환.

#### 벡터화 종류
- **원-핫 벡터**: 고차원 희소 벡터, 단어 집합 크기만큼 차원 확장, 0과 1로 구성.
- **임베딩 벡터**: 저차원 밀집 벡터, 실수값, 학습 데이터에 의존.

#### 관련 용어
- **분산 표현**: 단어를 다차원 벡터로 표현.
- **임베딩**: 문자열의 유사성을 벡터화하는 작업.
- **코사인 유사도**: 두 벡터 간 각도를 통해 유사성 측정.

#### Word2Vec

- **CBOW**: 주변 단어로 중심 단어 예측.
- **Skip-gram**: 중심 단어로 주변 단어 예측.


#### Transformer 모델

- Encoder-Decoder 구조, Attention 메커니즘 활용.

#### 주요 개념
- **Positional Encoding**: 순서 정보 추가.
- **Multi-head Attention**: 병렬 처리로 성능 향상.

#### 생성형 AI (Generative AI)

텍스트, 이미지, 음악 등 다양한 형식의 응답을 생성하는 AI.

#### LLM(대규모 언어 모델) 관련 용어
- **임베딩**: 문자열 유사성을 벡터화.
- **Attention**: 특정 정보에 가중치를 부여하여 연산.
- **Bias**: 불균형 데이터로 인해 잘못된 응답을 하는 경우.

#### LLM 평가 기준
- **RLHF**: 인간 피드백 기반 강화학습.
- **AI Feedback**: AI 기반 응답 평가.

#### LLM 응답 방식
- **Fine-tuning**: 모델을 추가 학습.
- **RAG**: 외부 데이터를 참조하여 응답 생성.
- **프롬프트 엔지니어링**: 모델의 답변 스타일을 조정.

#### 프롬프트 엔지니어링

LLM의 답변 스타일을 조정하고 성능을 향상시키는 기술.

#### 성공적인 프롬프트의 조건
- 구체적이고 정량적인 기준 제시.
- 역할과 상황을 명시한 프롬프트 사용.

#### 프롬프트 유형
- **Zero-shot**: 질문만 제시.
- **One-shot**: 예시 하나 포함.
- **Few-shot**: 복수의 예시 포함.

#### Fine-tuning과 RAG

- **Fine-tuning**: LLM을 특정 분야에 맞춰 추가 학습.
- **RAG**: 외부 문서를 참조하여 신뢰도 높은 응답 생성.

#### 문서 검색 시스템

FAISS 벡터 DB를 생성해 검색 기능을 구현.

- **코사인 유사도**: SentenceTransformers 모델을 활용해 문장 비교.

#### Huggingface Transformers 라이브러리

NLP 모델 추상화와 다양한 모델 지원.

- **감정 분석 모델**: Huggingface에서 제공하는 모델로 감정 분석 수행 가능.

### 2. ADsP
- 기출변형풀기

### 3. SQLD
- 3과목 공부
---
## 어려웠던 내용
- 복습 내용
- ADsP
---
## 궁금한 내용과 부족한 내용
- 없다
---
## 느낀 점
- 화이팅

<!-- <img src="이미지 주소" width="100%" height="100%"/> -->
