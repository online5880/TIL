## Today I Learned (2024-07-26) 🤔
---
> ## 목차
- [Today I Learned (2024-07-26) 🤔](#today-i-learned-2024-07-26-)
- [오늘 공부한 내용 🧑🏻‍💻](#오늘-공부한-내용-)
  - [1. KDT](#1-kdt)
    - [**특강**](#특강)
  - [2. Doit! 쉡게 배우는 파이썬 데이터 분석 (도서)](#2-doit-쉡게-배우는-파이썬-데이터-분석-도서)
    - [데이터 분석 프로젝트 - 한국인의 삶을 파악하라!](#데이터-분석-프로젝트---한국인의-삶을-파악하라)
- [어려웠던 내용 📚](#어려웠던-내용-)
- [궁금한 내용과 부족한 내용 🙋🏻](#궁금한-내용과-부족한-내용-)
- [느낀 점 💡](#느낀-점-)
---

## 오늘 공부한 내용 🧑🏻‍💻
### 1. KDT
#### **특강**
- 오늘은 AI센터장님이 오셔서 특강을 해주셨다. 주요 내용은 다음과 같다:
  - **데이터 파이프라인**: 데이터를 수집, 처리, 저장, 분석하는 전 과정
  - **학습 데이터**: 모델 학습에 사용되는 데이터의 중요성과 준비 방법
  - **xAPI 및 캘리퍼**: 학습 분석 표준과 데이터 상호 운용성
  - **데이터 웨어하우스, 데이터 레이크, 데이터 마트**: 데이터 저장 및 관리 방법의 차이
  - **프로세스 마이닝**: 비즈니스 프로세스 분석 방법
---
### 2. Doit! 쉡게 배우는 파이썬 데이터 분석 ([도서](https://m.yes24.com/Goods/Detail/108947478))
#### 데이터 분석 프로젝트 - 한국인의 삶을 파악하라!
- 지역별 연령대 비율 - 어느 지역에 노년층이 많을까?
- 분석 단계
  1. 변수 검토 및 전처리
      - 지역
      - 연령대
  2. 변수 간 관계 분석
      - 지역별 연령대 비율표 만들기
      - 그래프 만들기
---
- **지역 변수 검토**
  - **지역 코드 변수 타입 확인**
    - 지역 코드의 어떤 타입인지 확인한다.
      ```python
      welfare['code_region'].dtyoes # 변수 타입 출력
      ```
      ```python
      dtype('float64')
      ```
  - **지역 빈도 확인**
    - 지역 마다 빈도수(인구수?)를 확인한다.
      ```python
      welfare['code_region'].value_counts()
      ```
      ```python
      code_region
      2.0    3246
      7.0    2466
      3.0    2448
      1.0    2002
      4.0    1728
      5.0    1391
      6.0    1137
      Name: count, dtype: int64
      ```
  - **전처리 하기**
    - 책에 나와 있는 지역 코드 목록을 만든다.
      ```python
      # 전처리하기
      # 1. 서울
      # 2. 수도권(인천/경기)
      # 3. 부산/경남/울산
      # 4. 대구/경북
      # 5. 대전/충남
      # 6. 강원/충북
      # 7. 광주/전남/전북/제주도

      # 지역 코드 목록 만들기
      list_region = pd.DataFrame(
          {
              "code_region": [1, 2, 3, 4, 5, 6, 7],
              "region": [
                  "서울",
                  "수도권(인천/경기)",
                  "부산/경남/울산",
                  "대구/경북",
                  "대전/충남",
                  "강원/충북",
                  "광주/전남/전북/제주도",
              ],
          }
      )

      list_region
      ```
      ```python
        code_region	region
      0	  1	        서울
      1	  2	        수도권(인천/경기)
      2	  3	        부산/경남/울산
      3	  4	        대구/경북
      4	  5	        대전/충남
      5	  6	        강원/충북
      6	  7	        광주/전남/전북/제주도
      ```
  - **지역 코드를 중심으로 지역명 merge 시키기**
      - 데이터프레임의 merge 기능을 통해 `code_region`을 기준으로 합친다.
        ```python
        # 지역명 변수 추가
        welfare = welfare.merge(list_region, how="left", on="code_region")

        welfare.region
        ```
        ```python
        0           서울
        1           서울
        2           서울
        3           서울
        4           서울
                ...  
        14413    대전/충남
        14414    대전/충남
        14415    대전/충남
        14416    대전/충남
        14417    대전/충남
        Name: region, Length: 14418, dtype: object
        ```
  - **지역별 연령대 비율표 만들기**
    - ```python
      # region별 분리
      # ageg 추출
      # 비율 구하기
      region_ageg = welfare.groupby("region", as_index=False)["ageg"].value_counts(
          normalize=True
      )

      # 그래프 만들기
      # 백분율로 바꾸기
      # 반올림
      region_ageg = region_ageg.assign(proportion=region_ageg["proportion"] * 100).round(1)
      ```
      
  - **지역별 연령대 비율을 나타낸 그래프 만들기**
    - `seaborn`의 barplot을 이용해 막대 그래프를 만든다.
    - `x` : young, middle, old 의 나이 평균 비율이다.
    - `y` : 지역
    - `hue` : 연령
      ```python
      # 막대 그래프 만들기
      sns.barplot(data=region_ageg, x="proportion", y="region", hue="ageg")
      ```
      ![alt text](https://github.com/online5880/TIL/blob/main/Images/2024_07_26/doit_01.png?raw=true)
  - **피벗하기**
    - 행과 열을 회전해 표의 구성을 바꾸는 작업을 피벗이라고 한다.
      - 지역을 기준으로 회전하도록 `index = 'region'`
      - 연령대별로 열을 구성하도록 `columns = 'ageg'`
      - 각 항목의 값을 비율로 채우도록 `values = 'proportion'`
        ```python
        # 피벗하기

        pivot_df = region_ageg[['region','ageg','proportion']].pivot(
            index='region',
            columns='ageg',
            values='proportion'
        )

        # 막대 정렬하기
        reorder_df = pivot_df.sort_values('old')[['young','middle','old']]
        ```

        ```python
        ageg	young	middle	old
        region			
        수도권(인천/경기)	28.7	38.8	32.5
        서울	23.9	38.5	37.6
        대전/충남	25.0	33.6	41.3
        부산/경남/울산	22.9	33.4	43.8
        광주/전남/전북/제주도	23.3	31.8	44.9
        강원/충북	23.2	30.9	45.9
        대구/경북	20.0	29.6	50.4
        ```
        ![alt text](https://github.com/online5880/TIL/blob/main/Images/2024_07_26/doit_02.png?raw=true)
---
## 어려웠던 내용 📚
- 특강의 내용이 처음 들어보는 것들이 많아서 이해하기가 쉽진 않았다.
- 용어도 처음 들어보는게 많았기 때문이다.
---
## 궁금한 내용과 부족한 내용 🙋🏻
- 데이터 웨어하우스, 데이터 레이크, 데이터 마트 [[참고](https://mujilog.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%9B%A8%EC%96%B4%ED%95%98%EC%9A%B0%EC%8A%A4%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%ED%8A%B8%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A0%88%EC%9D%B4%ED%81%AC-%EB%9E%80)]
  - `데이터 웨어하우스` : 
    - 데이터(정보) + 웨어하우스(창고)의 합성어
    - **많은 양의 데이터를 오래 보관하는 것에 최적화되어있다.**
  - `데이터 레이크` :
    - 모든 형태의 데이터를 원래의 형태로 적재
  - `데이터 마트` : 
    - 데이터 웨어하우스의 데이터를 이용하여 분석 및 개발이 필요할 경우, **필요한 데이터를 추출하여 데이터 마트를 따로 구축한다.**
    - 전사적인 데이터를 보관하는 데이터 웨어하우스와 달리, 특정 목족에 따라 추출하여 사용한다.
  
| **항목**        | **데이터 웨어하우스 (Data Warehouse)**                         | **데이터 마트 (Data Mart)**                                  | **데이터 레이크 (Data Lake)**                                |
| --------------- | -------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **정의**        | 여러 데이터 소스로부터 ETL 과정을 거쳐 통합된 데이터 창고 구축 | 데이터 웨어하우스에서 필요한 데이터를 추출하여 구축          | 가공되지 않은 형태의 원시 데이터를 저장하는 데이터 저장소    |
| **데이터 형태** | 구조화된 데이터                                                | 특정 목적에 맞게 추출된 데이터                               | 미가공된 원시 데이터                                         |
| **목적**        | 업무적으로 중요한 데이터를 전사적 관점에서 통합하여 관리       | 특정 분석 및 개발 목적을 위해 필요한 데이터 저장             | 다양한 포맷의 데이터를 원래 형태로 저장하고 필요 시 가공     |
| **데이터 사용** | 많은 양의 데이터를 오랫동안 보관                               | 분석 및 개발 필요 시 데이터 웨어하우스에서 추출하여 사용     | Ad-hoc 분석 및 머신러닝에 효율적으로 사용                    |
| **데이터 관리** | 통합 관리                                                      | 특정 목적에 따라 관리                                        | 필요에 따라 가공                                             |
| **주요 특징**   | - 전사적으로 중요한 데이터 저장<br>- 아무때나 함부로 사용 불가 | - 데이터 웨어하우스 데이터를 이용<br>- 특정 목적에 맞게 구축 | - 원시 데이터를 그대로 저장<br>- 다양한 관점에서의 분석 가능 |

![alt text](https://github.com/online5880/TIL/blob/main/Images/2024_07_26/Modern_Data_Architecture.png?raw=true)

---
## 느낀 점 💡
- 특강 시간에 새로 접하는 내용이 많아서 어렵기도 하였지만 앞으로 더 배우면서 재미있을 것 같다.
