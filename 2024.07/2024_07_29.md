## Today I Learned (2024-07-29) 🤔 Monday 
---
> ## 목차
- [오늘 공부한 내용 🧑🏻‍💻](#오늘-공부한-내용-🧑🏻‍💻)
  - [1. 인프런 - 핵심만 빠르게, 입문자를 위한 파이썬(Python)과 판다스(Pandas)](#1-인프런---핵심만-빠르게-입문자를-위한-파이썬python과-판다스pandas)
    - [**데이퍼 프레임**](#데이퍼-프레임)
  - [2. Doit! 쉡게 배우는 파이썬 데이터 분석 (도서)](#2-doit-쉡게-배우는-파이썬-데이터-분석-도서)
    - [통계 분석 기법](#통계-분석-기법)
    - [가설 검정](#가설-검정)
    - [t 검정(t-test)](#t-검정t-test)
    - [상관분석](#상관분석)
- [어려웠던 내용 📚](#어려웠던-내용-📚)
- [궁금한 내용과 부족한 내용 🙋🏻](#궁금한-내용과-부족한-내용-🙋🏻)
- [느낀 점 💡](#느낀-점-💡)
---

## 오늘 공부한 내용 🧑🏻‍💻
### 1. [인프런](https://www.inflearn.com/course/%ED%95%B5%EC%8B%AC-%EC%9E%85%EB%AC%B8%EC%9E%90-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%8C%90%EB%8B%A4%EC%8A%A4/dashboard) - 핵심만 빠르게, 입문자를 위한 파이썬(Python)과 판다스(Pandas)
#### **데이퍼 프레임**
- 데이터 수정하기
  - 수정은 대입 연산자만 넣으면 끝이다..?
- 데이터 삭제하기
  - `dataframe.drop(axis)`
    - 열 : axis = 0 
    - 행 : axis = 1
    - 판다스는 데이터 보호를 위해 drop 메서드를 사용했다고 해서, 원본 데이터를 삭제하지 않는다.
- 중복 데이터 찾기
  - `dataframe.duplicated(subset=, keep=)`
    - `subset` : 특정 컬럼에 대한 중복만 처리 가능
    - `keep` : 어떤 값을 중복으로 인식할 것인가를 설정, 기본값은 `first`
  - 중복되는 값은 `True` 를 반환한다.
- 중복 데이터 삭제
  - `dataframe.drop_duplicates(subset=, keep=)`
    - `subset` : 특정 컬럼에 대한 중복만 처리 가능
    - `keep` : 어떤 값을 중복으로 인식할 것인가를 설정, 기본값은 `first`
- 결측(빈) 데이터 처리
  - `isnull (isna)` : 결측치 찾기
    - 값이 비어 있으면 `True` 를 반환한다.
  - `fillna()` : 결측치 채우기
    - `dataframe.fillna(1)` : 특정 값으로 패우기
    - `dataframe.fillna(method = 'ffill')` : ffill = forwardfill 앞에 값으로 대체
    - `dataframe.fillna(method = 'bfill')` : bfill = backwardfill 뒤에 값으로 대체
  - `dropna()` : 결측치 제거
- #### **pandas 연산**
  - pandas 의 axis 는 대부분 기본값이 axis =0 이다.
  - `sum()` : 합계
  - `divide()` : 나누기
  - `cumprod()` : 누적곱
  - `cummax()` : 누적 최댓값
  - `cummin()` : 누적 최소값
- #### pandas **apply() 함수**
  - 데이터 프레임에 파이썬 함수를 적용할 수 있다.
    ```python 
    # 인자는 row
    def getVolume(row):
        return row.가로 * row.세로 * row.높이


    df["부피"] = df.apply(getVolume, axis=1)
    df
    ```
    ```python
          가로	세로	높이	부피
    0	    10	  20	  50	  10000
    1	    20	  23	  40	  18400
    2   	30	  22	  20	  13200
    3   	10	  33	  50	  16500
    4	    30	  22	  20	  13200
    5	    20	  12	  30	  7200
    6   	11	  11	  40	  4840
    ```
---
### 2. Doit! 쉡게 배우는 파이썬 데이터 분석 ([도서](https://m.yes24.com/Goods/Detail/108947478))
#### 통계 분석 기법
#### 가설 검정
- **기술 통계**
  - 데이터를 요약해 설명하는 통계 분석 기법
  - 예) 사람들이 받는 월급을 집계해 전체 월급 평균을 구하는 것
- **추론 통계**
  - 어떤 값이 발생할 확률을 계산하는 통계 분석 기법
  - 예) 데이터에서 성별에 따라 월급에 차이가 있는 것이 나타났을 때, 이런 차이가 우연히 발생할 확률을 계산하는 것
  
> 일반적으로 통계 분석을 수행했다는 것은 추론 통게를 이용해 가설 검정을 했다는 의미이다.

- **통계적 가설 검정**
  - 유의확을을 이용해 가설을 검정하는 방법
  - 유의확율은 실제로 집단 간 차이가 없는데 우연히 차이가 있는 데이터가 추출될 확률
  
---
#### t 검정(t-test)
- **t 검정(t-test)란?**
  - 두 집단의 평균에 통계적으로 유의한 차이가 있는지 알아볼 때 사용하는 통계 분석 기법이다.
  - 예시 코드
    ```python
    import pandas as pd

    mpg = pd.read_csv("../data/mpg.csv")

    # 기술 통계 분석
    # compact, suv 추출하기
    # category 별 분리
    # 빈도 구하기
    # cty 평균 구하기
    mpg.query('category in ["compact", "suv"]').groupby("category", as_index=False).agg(
        n=("category", "count"), mean=("cty", "mean")
    )
    ```
    ```bash
    category	n	mean
    0	compact	47	20.12766
    1	suv	62	13.50000
    ```
    - `compact` 와 `suv` 자동차의 도시 연비 차이 통계적으로 유의한지
    ```python
    # compact 와 suv 자동차의 도시 연비 차이 통계적으로 유의한지
    compact = mpg.query('category == "compact"')["cty"]
    suv = mpg.query('category == "suv"')["cty"]

    # t - test
    from scipy import stats

    stats.ttest_ind(compact, suv, equal_var=True)
    ```
    ```bast
    TtestResult(statistic=11.917282584324107, pvalue=2.3909550904711286e-21, df=107.0)
    ```
    ```bash
    p-value : 유의미한 확률
    일반적으로 유의확률 5%를 판단 기준으로 삼고, p-value가 0.05미만이면 '집단 간 차이가 통계적으로 유의하다'고 해석한다.
    즉, compact 와 suv 간 평균 도시 연비 차이가 통계적으로 유의하다고 결론 내릴 수 있다.
    ```
---
#### 상관분석
- **상관분석이란?**
  - 두 연속 변수가 서로 관련 있는지 검정하는 통계 분석 기법이다.
  - `상관계수` : 0~1 사이의 값을 지니며 1에 가까울수록 관련성이 크다는 것을 의미한다.
  - `dataframe.corr()` : 상관계수를 구할 수 있다.
  - 예시 코드
    ```python
    # 실업자 수와 개인 소비 지출의 상관 관계

    # 1. 상관계수 구하기
    # df.corr() 을 이용해 구할 수 있다.
    import pandas as pd

    # economics 데이터 불러오기
    economics = pd.read_csv("../data/economics.csv")

    # 상관행렬 만들기
    economics[["unemploy", "pce"]].corr()
    ```
    > 상관계수가 양수 0.61이므로, 실업자 수와 개인 소비 지출은 한 변수가 증가하면 다른 변수가 증가하는 정비례 관계
    
    ```python
    # 2. 유의확률 구하기
    # scipy 패키지의 stats.perasonr()

    from scipy import stats

    stats.pearsonr(economics["unemploy"], economics["pce"])
    # 첫 번째 값(statistic) : 상관계수
    # 두 번째 값(pvalue) : 유의확률
    ```
    ```bast
    PearsonRResult(statistic=0.6145176141932083, pvalue=6.773527303289381e-61)
    ```
---
## 어려웠던 내용 📚
- 통계 분석 기법들...
  - 처음 보는 용어들이였다. 🥹
---
## 궁금한 내용과 부족한 내용 🙋🏻
- 실습했던 문제들을 내가 제대로 이해하고 푼건지 잘 모르겠다..
---
## 느낀 점 💡
- 통계 분석 기법들을 처음 봐서 어려웠다.
- 데이터 시각화 하는 것이 어려웠다.
- 그래도 재미있다



