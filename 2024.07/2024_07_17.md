## Today I Learned (2024-07-17) 🤔

### 오늘 공부한 내용 🧑🏻‍💻

#### 1. 파이썬

- **self**
  - `self`를 쓰지 않는 메서드는 존재하는가
    - 결론은 안 쓰고 사용할 수 있다.
    - 예를 들어 유틸리티 함수를 만들어서 사용할 수 있다.
      - 예시 코드
        ```python
        class MathUtils:
            def add(a, b):
                return a + b

            def subtract(a, b):
                return a - b

        # 정적 메서드 호출
        print(MathUtils.add(5, 3))      # 8
        print(MathUtils.subtract(5, 3)) # 2
        ```
        > 위와 같은 함수들은 인스턴스나 클래스 변수에 접근할 필요가 없기 때문에 정적 메서드로 정의할 수 있다.

#### 2. 인프런(나도코딩) 🌱

- **Section 8**
  - 클래스
    - 클래스의 기본 구조와 생성
      - 예시 코드
        ```python
        class Unit:
            def __init__(self, name, hp, damage):
                self.name = name
                self.hp = hp
                self.damage = damage
                print(f"{name} 유닛이 생성되었습니다.")
                print(f"체력 {hp}, 공격력 {damage}")

        marine1 = Unit("마린", 40, 5)
        marine2 = Unit("마린", 40, 5)
        tank = Unit("탱크", 150, 35)
        ```

#### 3. KDT(천재교육)

- **HTML 파싱**
  - 파싱(parsing): 텍스트 데이터를 `분석`하여 `구조화`하고, 필요에 따라 특정 데이터를 `추출`하는 작업
  - 크롤링(crawling): `웹 크롤러 로봇`이 자동으로 웹 사이트를 이동하며 정보를 수집하는 것
    - `robots.txt`: 웹 사이트의 루트 주소에 접근할 수 있으며, 웹 크롤러 봇의 접근 권한을 관리하는 파일
      - [참고사이트](https://seo.tbwakorea.com/blog/robots-txt-complete-guide/)
  - 스크래핑(scraping): 특정 웹 페이지의 특정 부분을 수집하는 것
  - **Beautiful Soup** 라이브러리
    - `Beautiful Soup` 란? HTML 문서를 분석 & 구조화해서 개발자가 도와주는 도구 (크롤링 도구가 아닌 파싱 도구)
    - `Beautiful Soup` 객체: HTML 문서를 파이썬 객체로 변환하여 탐색 가능하게 해주는 객체
    - 사용법: `from bs4 import BeautifulSoup`
    - 예시 코드
      ```python
      import requests
      from bs4 import BeautifulSoup

      # 요청 주소
      url = "https://example.com"

      # 요청 - get(url) 메서드
      response = requests.get(url)

      # 상태 코드 속성
      status = response.status_code

      if status == 200:

            # beautifulsoup 객체 생성
            # html.parser 유형
            soup = BeautifulSoup(response.text, "html.parser")

            # BeautifulSoup.find(태그이름) : 단일 탐색 메서드 -> 처음 나온 요소만 반환한다.
            p_tag = soup.find("p")
            print(p_tag.text)

            # soup 인스턴스 내부에서 H1 태그를 찾아서 텍스트를 출력
            h1_tag = soup.find("h1")
            print(h1_tag.text)
      ```

  - **요소(element) 탐색**
    - 단일 요소 탐색: `BeatifulSoup.find(name, attrs)`
      - name : 찾는 태그 이름 ex) “p”, “div”, “hi”
      - attrs : 속성 조건을 딕셔너리로 작성 ex) {”class”:”text”} → 클래스 이름이 “text” 인 요소를 찾는다.
      ```python
      p_tag = soup.find("p")
      print(p_tag.text)
      ```
    - 복수 요소 탐색: `BeautifulSoup.findAll(name, attrs)`
      - name : 찾는 태그 이름 ex) “p”, “div”, “hi”
      - attrs : 속성 조건을 딕셔너리로 작성 ex) {”class”:”text”} → 클래스 이름이 “text” 인 요소를 찾는다.
      - 아무것도 받아오지 못했어도 `빈 리스트([])`를 반환한다.
      ```python
      import requests
      from bs4 import BeautifulSoup

      url = "https://quotes.toscrape.com/"
      response = requests.get(url)
      status = response.status_code

      if status == 200:
          soup = BeautifulSoup(response.text, "html.parser")

          # 복수 요소 탐색
          # span 태그, class가 text인 모든 요소의 텍스트 출력
          quote_text_list = soup.find_all("span", {"class": "text"})
          for text in quote_text_list:
              print(text.text)
      ```
      - **단일 요소, 복수 요소 탐색을 모두 사용한 예시 코드**
          ```python
            import requests
            from bs4 import BeautifulSoup

            url = "https://quotes.toscrape.com/"
            response = requests.get(url)

            status = response.status_code

            if status == 200:
                # beautifulsoup 생성
                soup = BeautifulSoup(response.text, "html.parser")

                div_list = soup.findAll("div", {"class": "quote"})

                quote_author_list = []

                for quote in div_list:
                    # 태그 span,  클래스 text 요소 탐색
                    quote_text = quote.find("span", {"class": "text"}).text

                    # 인물 정보 탐색
                    # 태그 samll, 클래스 author 요소 탐색
                    author_text = quote.find("small", {"class": "author"}).text

                    # quote_author_list 에 저장
                    # {"quote" : 인용문데이터,"author":인물 데이터}
                    # quote_author_list 에 저장(추가 append)
                    quote_author_list.append(
                        {
                            "quote": quote_text,
                            "author": author_text,
                        }
                    )
          ```

- **pprint 모듈**
  - 데이터를 보기 좋게 출력(pretty print)할 때 사용하는 모듈
  - [pprint 모듈 설명](https://wikidocs.net/105471)

- **웹 브라우저 자동화 도구**
  - **Selenium**
    - `selenium` : 웹 브라우저를 자동으로 제어할 수 있는 도구
    - 설치: `pip install selenium`
    - **webdriver-manager**
      - 브라우저 자동화를 위한 웹 드라이버 관리 패키지
      - 설치: `pip install webdriver-manager`

---

- **WebDriver 객체**
  - 웹 브라우저를 제어하는 데 사용되는 핵심 객체
  - 주요 메서드 및 속성
    - `webdriver.Chrome()` : 크롬용 WebDriver 객체 생성
    - `webdriver.get(주소)` : 해당 주소의 웹 페이지 열기
      ```python
      from selenium import webdriver
      from selenium.webdriver.chrome.service import Service
      from webdriver_manager.chrome import ChromeDriverManager

      service = Service(ChromeDriverManager().install())
      driver = webdriver.Chrome(service=service)
      driver.get("https://www.naver.com")
      driver.quit()
      ```
      - 코드 분석
        - 1) Selenium 및 필요한 모듈 임포트
            ```python
            from selenium import webdriver
            from selenium.webdriver.chrome.service import Service
            from webdriver_manager.chrome import ChromeDriverManager
            ```
            - `selenium` : 웹 브라우저 자동화를 위한 라이브러리
            - `webdriver` : Selenium WebDriver를 사용하기 위해 필요
            - `Service` : ChromeDriver 서비스를 설정하기 위해 사용
            - `ChromeDriverManager` : ChromeDriver를 자동으로 설치하고 관리하는 라이브러리
        - 2) ChromeDriver 서비스 설치 및 설정
            ```python
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service)
            ```
            - `ChromeDriverManager().install()` : ChromeDriver를 자동으로 다운로드하고 설치한다.
            - `Service()` : 설치된 ChromeDriver를 서비스로 설정한다.
            - `webdriver.chomre(serivce=service)` : 설정된 서비스를 사용하여 Chrome 브라우저 인스턴스를 생성한다.
        - 3) 주소에 해당하는 웹페이지 열기
            ```python
            driver.get("https://naver.com")
            ```
            - `driver.get(url)` : 주어진 URL로 브라우저를 연다. Selenium WebDriver 가 해당 페이지로 이동한다.
        - 4) 브라우저 닫기
            ```python
            driver.quit()
            ```
            - `driver.quit()` : WebDriver 세션을 종료하고 브라우저 창을 닫는다.
    - `webdriver.find_element(조건, 값)` : 조건과 값에 해당하는 요소 중 처음 찾은 단일 요소 반환
      ```python
      from selenium.webdriver.common.by import By 
      p_tag = driver.find_element(By.TAG_NAME, "p").text
      print(p_tag)
      ```
      - 코드 분석
        - `By` : 요소를 찾기 위한 조건을 설정하는 데 사용된다. 예를 들어, 태그 이름, 클래스 이름, ID 등을 지정할 수 있다.
        - `driver.find_element(By.TAG_NAME,"p").text` : 페이지에서 첫 번째 `<p>` 태그 요소를 찾는다. 그리고 요소의 텍스트 내용을 반환한다.
        - 나머지는 위와 동일
    - `webdriver.find_elements(조건, 값)` : 조건과 값에 해당하는 모든 요소 반환
      ```python
      quote_text_list = driver.find_elements(By.CLASS_NAME, "text")
      for quote in quote_text_list:
          print(quote.text)
      ```
    - `webdriver.click()` : 해당 요소에 대해 클릭 상호작용 실행
      ```python
      # 검색 박스 찾기
      search_box = driver.find_element(By.ID, "query")

      # 파이썬 입력
      search_box.send_keys("Python")

      # 검색 버튼 찾기
      button = driver.find_element(By.CLASS_NAME, "btn_search")
      
      # 버튼 누르기
      button.click()
      ```
    - `webdriver.page_source` : 현재 페이지의 HTML 문서 정보
    - **대기(wait) 매커니즘**
      - `암시적 대기(Implicit Wait)`
        ```python
        driver.implicitly_wait(10)
        try:
            element = driver.find_element(By.CLASS_NAME, "element_class")
            print("조건에 만족하는 요소를 찾았습니다.")
        except:
            print("조건을 만족하는 요소를 찾지 못했습니다.")
        driver.quit()
        ```
      - `Explicit Wait(명시적 대기)`: 특정 조건을 만족할 때까지 최대 시간(초) 만큼 대기 (수업 시간에 넘어감)
---
### 어려웠던 내용 📚

- 암시적, 명시적 대기
- 요소 찾기
- html 문서에 접근해서 요소 가져오기
  - 태그들이 너무 많아서 헷갈렸다
---
### 궁금한 내용과 부족한 내용 🙋🏻

- 암시적, 명시적을 어떻게 사용되는지 더 찾아봐야겠다.

---
### 느낀 점 💡

- 솔직히 한 번에 외워지지 않을 것을 안다... 나는 써보면서 익혀야겠다.
- 파이썬 라이브러리를 활용해서 스크래핑 하는게 신기했다. 내가 브라우저를 열지 않아도 코드 열고 닫고 앞으로가 더 기대된다.
---